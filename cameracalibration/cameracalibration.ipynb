{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d057d264-d319-432f-9810-4c4267fcd810",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This is Tutorial for the Camera Calibration using OpenCV from link\n",
    "'https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d616b02",
   "metadata": {},
   "source": [
    "# Procedure for Camera Calibration:\n",
    "\n",
    "1. Capture more images to calibrate camera more precisely.\n",
    "2. In this tutorial we have captured ~300 images\n",
    "\n",
    "# Guidlines to Capture Images:\n",
    "\n",
    "1. Take the chessboard and place it on any corner of the setup\n",
    "2. Move the chessboard all over the setup and capture images\n",
    "3. Capture images at different height and angles (The board angle should not be more than 45Â°)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15264803-e782-4ad6-ab7b-1a81037deea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Steps(By using docker file) ;\n",
    " \n",
    "  1. Build the DockerImage by running: $sudo docker build ./ --tag  bfs-image-publisher (without calibration.yaml)\n",
    "  \n",
    "  2. Run the DockerImage by running:  $sudo docker run -t --privileged -v /dqev/bus/usb:/dev/bus/usb -p 5557:5557 -p 5556:5556 bfs-      image-publisher\n",
    "  \n",
    "  3. Run the Subscriber code in conda environment using: $python3 camerasubscriber.py and RUN python3 calibration.py --     save_img.true in the command line to capture the images\n",
    "  \n",
    "  4. Collect the images by placing the target at different positions and angles\n",
    "  \n",
    "  5. follow the next cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d44c0",
   "metadata": {},
   "source": [
    "# Example of carrera setup (Original Image)\n",
    "![](Original.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121cdcc",
   "metadata": {},
   "source": [
    "# Example of carrera setup (Calibrated Image)\n",
    "![](Calibrated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb159bb",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7ff4d-0399-4179-828a-8b44a1a8f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b6e90",
   "metadata": {},
   "source": [
    "# Defining object points, criteria and Reading captured images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a48a7-bd52-4b89-91f4-7d990742154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Defining the world coordinates for 3D points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:6,0:9].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('../subscriber/data/img/temp_img_data/*.png')\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25879b6",
   "metadata": {},
   "source": [
    "# Extracting path of individual image stored in a given directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca72036-7105-4f0d-acd9-f00ada42b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    #img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)# TODO COLOR\n",
    "    gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)# TODO COLOR\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (6,9), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # refining pixel coordinates for given 2d points.\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (6,9), corners2, ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29735df7",
   "metadata": {},
   "source": [
    "# Performing camera calibration\n",
    "\n",
    "The mtx and dst values are stored in yaml file for the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d3f26-b117-44f6-8049-e8e772025a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing camera calibration by passing the value of known 3D points (objpoints)\n",
    "and corresponding pixel coordinates of the detected corners (imgpoints)\n",
    "\"\"\"\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "print(mtx)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659227f4",
   "metadata": {},
   "source": [
    "# Creation of config file for camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa554-ce8a-4062-ab1b-fca71e8fea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml code implementation\n",
    "with open('../bfs-camera-driver/publisher/calibration.yaml') as fh:\n",
    "    read_data = yaml.load(fh, Loader = yaml.FullLoader)\n",
    "    \n",
    "    # Reading Elementss from the yaml file\n",
    "    matx = read_data['camera_matrix']\n",
    "    dist_coeff = read_data['dist_coeff']\n",
    "    \n",
    "    # Printing yaml file values\n",
    "    print('Camera Matrix ; ', matx)\n",
    "    print('Distance Coefficients : ', dist_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf7677",
   "metadata": {},
   "source": [
    "# Steps( By using yaml file)\n",
    "1. Create a yaml file which contains the value of camera matrix and distance coefficients obtsined from 'mtx' and 'dst' in code below.\n",
    "\n",
    "2. Run the publisher code in conda environment using $python3 camerapublisher.py.\n",
    "\n",
    "3. Run the Subscriber code in conda environment using $python3 camerasubscriber.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36178753",
   "metadata": {},
   "source": [
    "# Test Results: Reading image to undisort it\n",
    "The function 'cv.getOptimalNewCameraMatrix' computes and returns the optimal new camera intrinsic matrix based on the free scaling parameter\n",
    "\n",
    "cv.getOptimalNewCameraMatrix(cameraMatrix, distortion Coefficient, imgSize, alpha=1, newImgSize(should be equal to imgSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5226762-7f56-4029-b0df-a63c6ac47ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('464955.png')\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "print(newcameramtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec2f45",
   "metadata": {},
   "source": [
    "# Undistortion Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a6bc0-7d6d-4587-8796-2e4627847410",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "print(dist)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst1 = dst[y:y+h, x:x+w]\n",
    "print(dst.shape)\n",
    "\n",
    "# Writing image to directory\n",
    "cv.imwrite('new_final13.png', dst1)\n",
    "\n",
    "# plotting original and calibrated image\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(dst)\n",
    "plt.title('Calibrated Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fed62",
   "metadata": {},
   "source": [
    "# Undistortion Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f95b79-e6f0-4e62-8aa2-b771bc1168a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w+x, h+y), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "print(dst.shape)\n",
    "cv.imwrite('new_calibresult_final11.png', dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
